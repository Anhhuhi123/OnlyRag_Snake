# BERTScore Evaluation for RAG System

## ğŸ“ MÃ´ táº£

File `evaluate_generation_bertscore.py` Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng cÃ¢u tráº£ lá»i cá»§a LLM báº±ng **BERTScore** - má»™t metric Ä‘o Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng ngá»¯ nghÄ©a dá»±a trÃªn BERT embeddings.

## ğŸ¯ Má»¥c Ä‘Ã­ch

So sÃ¡nh cÃ¢u tráº£ lá»i cá»§a LLM (`answer`) vá»›i cÃ¢u tráº£ lá»i Ä‘Ãºng (`ground_truth`) Ä‘á»ƒ Ä‘Ã¡nh giÃ¡:
- **Precision**: Äá»™ chÃ­nh xÃ¡c - cÃ¢u tráº£ lá»i cÃ³ bao nhiÃªu thÃ´ng tin Ä‘Ãºng
- **Recall**: Äá»™ Ä‘áº§y Ä‘á»§ - cÃ¢u tráº£ lá»i bao phá»§ bao nhiÃªu % thÃ´ng tin cáº§n thiáº¿t
- **F1**: Äiá»ƒm cÃ¢n báº±ng giá»¯a Precision vÃ  Recall

## ğŸ“¦ CÃ i Ä‘áº·t

```bash
pip install bert-score
```

## ğŸš€ Sá»­ dá»¥ng

### Cháº¡y evaluation:

```bash
python evaluate_generation_bertscore.py
```

### Input:
- File: `data/predictions.json`
- Format:
```json
[
  {
    "question": "...",
    "ground_truth": "...",
    "answer": "...",
    "contexts": [...]
  }
]
```

### Output:
- File: `data/bertscore_evaluation_results.json`
- Chá»©a:
  - Average metrics (Precision, Recall, F1)
  - Per-question scores
  - Configuration info

## ğŸ“Š Káº¿t quáº£ máº«u

```
BERTScore Precision: 0.6612 Â± 0.0416
BERTScore Recall:    0.7883 Â± 0.0751
BERTScore F1:        0.7176 Â± 0.0477
```

### Score Distribution:
- **Excellent** (0.9-1.0): CÃ¢u tráº£ lá»i xuáº¥t sáº¯c
- **Very Good** (0.8-0.9): CÃ¢u tráº£ lá»i ráº¥t tá»‘t
- **Good** (0.7-0.8): CÃ¢u tráº£ lá»i cháº¥p nháº­n Ä‘Æ°á»£c
- **Fair** (0.6-0.7): CÃ¢u tráº£ lá»i trung bÃ¬nh
- **Poor** (<0.6): CÃ¢u tráº£ lá»i kÃ©m

## ğŸ”§ TÃ¹y chá»‰nh

Trong file `evaluate_generation_bertscore.py`:

```python
# Thay Ä‘á»•i model BERT
MODEL_TYPE = "xlm-roberta-base"  # Tá»‘t cho Ä‘a ngÃ´n ngá»¯
# hoáº·c
MODEL_TYPE = "bert-base-multilingual-cased"

# Thay Ä‘á»•i ngÃ´n ngá»¯
LANGUAGE = "en"  # Tiáº¿ng Anh
LANGUAGE = "vi"  # Tiáº¿ng Viá»‡t (máº·c Ä‘á»‹nh)
```

## ğŸ“ˆ Giáº£i thÃ­ch Metrics

### BERTScore Precision
- Äo lÆ°á»ng: Tá»· lá»‡ tokens trong predicted answer cÃ³ semantic match vá»›i ground truth
- Cao (>0.8): Ãt thÃ´ng tin sai/thá»«a
- Tháº¥p (<0.6): Nhiá»u thÃ´ng tin khÃ´ng liÃªn quan

### BERTScore Recall
- Äo lÆ°á»ng: Tá»· lá»‡ tokens trong ground truth Ä‘Æ°á»£c match bá»Ÿi predicted answer
- Cao (>0.8): Bao phá»§ Ä‘áº§y Ä‘á»§ thÃ´ng tin
- Tháº¥p (<0.6): Thiáº¿u nhiá»u thÃ´ng tin quan trá»ng

### BERTScore F1
- Äiá»ƒm tá»•ng há»£p (harmonic mean cá»§a P vÃ  R)
- Metric chÃ­nh Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ overall quality

## ğŸ†š So sÃ¡nh vá»›i metrics khÃ¡c

| Metric | Æ¯u Ä‘iá»ƒm | NhÆ°á»£c Ä‘iá»ƒm |
|--------|---------|------------|
| **BLEU** | Nhanh, Ä‘Æ¡n giáº£n | Chá»‰ Ä‘o n-gram overlap, khÃ´ng hiá»ƒu ngá»¯ nghÄ©a |
| **ROUGE** | Tá»‘t cho summarization | Chá»‰ Ä‘o overlap, khÃ´ng hiá»ƒu paraphrase |
| **BERTScore** | Äo ngá»¯ nghÄ©a, hiá»ƒu paraphrase | Cháº­m hÆ¡n, cáº§n GPU |
| **Cosine Similarity** | Äo tÆ°Æ¡ng Ä‘á»“ng tá»•ng thá»ƒ | KhÃ´ng chi tiáº¿t tá»«ng pháº§n |

## âš™ï¸ Best Practices

1. **Rescale with baseline**: LuÃ´n báº­t Ä‘á»ƒ scores dá»… interpret
2. **Model selection**: Chá»n model phÃ¹ há»£p vá»›i ngÃ´n ngá»¯
   - Tiáº¿ng Viá»‡t: `bert-base-multilingual-cased` (auto)
   - Äa ngÃ´n ngá»¯: `xlm-roberta-base`
3. **Batch processing**: BERTScore xá»­ lÃ½ theo batch â†’ nhanh hÆ¡n
4. **GPU acceleration**: Náº¿u cÃ³ GPU, tá»‘c Ä‘á»™ tÄƒng Ä‘Ã¡ng ká»ƒ

## ğŸ“ VÃ­ dá»¥ káº¿t quáº£

### Top Answer (F1: 0.8384)
```
Question: Ráº¯n Äƒn cua cÃ³ ná»c Ä‘á»™c Ä‘Æ°á»£c thiáº¿t káº¿ cho con má»“i nÃ o?
Ground Truth: Ná»c Ä‘á»™c nháº¹ Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t cho cua vÃ  cÃ¡...
Predicted: Ráº¯n Äƒn cua cÃ³ ná»c Ä‘á»™c Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t cho cua vÃ  cÃ¡...
â†’ High similarity! âœ…
```

### Low Answer (F1: 0.6338)
```
Question: Ráº¯n rÃ¡o nhiá»u Ä‘ai cÃ³ Ä‘á»™c khÃ´ng?
Ground Truth: KhÃ´ng, Ráº¯n rÃ¡o nhiá»u Ä‘ai lÃ  loÃ i khÃ´ng cÃ³ ná»c Ä‘á»™c.
Predicted: I couldn't find any relevant information...
â†’ Low similarity! âŒ
```

## ğŸ” Troubleshooting

### Error: "Model not found"
```bash
# Download láº¡i model
python -c "from transformers import AutoModel; AutoModel.from_pretrained('bert-base-multilingual-cased')"
```

### Cháº­m khi cháº¡y
- Giáº£m batch size trong code
- Sá»­ dá»¥ng GPU náº¿u cÃ³
- Chá»n model nháº¹ hÆ¡n

### Scores quÃ¡ tháº¥p
- Kiá»ƒm tra language code Ä‘Ãºng chÆ°a
- Thá»­ model khÃ¡c phÃ¹ há»£p hÆ¡n
- Kiá»ƒm tra quality cá»§a ground_truth vÃ  predictions

## ğŸ“š Tham kháº£o

- [BERTScore Paper](https://arxiv.org/abs/1904.09675)
- [BERTScore GitHub](https://github.com/Tiiiger/bert_score)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)

## ğŸ“ Support

Náº¿u cÃ³ váº¥n Ä‘á»:
1. Check logs trong terminal
2. Verify input file format
3. Test vá»›i data máº«u nhá» trÆ°á»›c
