# ğŸ“Š HÆ°á»›ng dáº«n Ä‘Ã¡nh giÃ¡ RAG vá»›i RAGAS

## ğŸ¯ Tá»•ng quan

Há»‡ thá»‘ng Ä‘Ã¡nh giÃ¡ RAG gá»“m 2 bÆ°á»›c:

1. **Generate Predictions**: Cháº¡y táº¥t cáº£ cÃ¢u há»i qua RAG pipeline â†’ sinh ra contexts vÃ  answer
2. **Evaluate with RAGAS**: ÄÃ¡nh giÃ¡ predictions báº±ng RAGAS metrics

## ğŸ“ Cáº¥u trÃºc Files

```
Input:  data/Eveluate.json      â†’ CÃ¢u há»i vÃ  ground truth
        â†“
Step 1: generate_predictions.py â†’ Sinh contexts + answer
        â†“
Output: data/predictions.json   â†’ CÃ³ Ä‘á»§ 4 trÆ°á»ng: question, ground_truth, contexts, answer
        â†“
Step 2: evaluate_ragas.py       â†’ ÄÃ¡nh giÃ¡ báº±ng RAGAS
        â†“
Output: evaluation_results.json â†’ RAGAS scores + chi tiáº¿t
        evaluation_results.csv  â†’ Báº£ng dá»¯ liá»‡u
```

## ğŸš€ CÃ i Ä‘áº·t

### 1. CÃ i Ä‘áº·t thÆ° viá»‡n RAGAS

```bash
pip install ragas datasets pandas
```

### 2. Kiá»ƒm tra file Eveluate.json

File `data/Eveluate.json` cáº§n cÃ³ Ä‘á»‹nh dáº¡ng:

```json
[
  {
    "question": "CÃ¢u há»i 1?",
    "ground_truth": "CÃ¢u tráº£ lá»i Ä‘Ãºng 1"
  },
  {
    "question": "CÃ¢u há»i 2?",
    "ground_truth": "CÃ¢u tráº£ lá»i Ä‘Ãºng 2"
  }
]
```

## ğŸ“ Sá»­ dá»¥ng

### BÆ¯á»šC 1: Generate Predictions

Cháº¡y táº¥t cáº£ cÃ¢u há»i qua RAG pipeline Ä‘á»ƒ sinh contexts vÃ  answer:

```bash
python generate_predictions.py
```

**Options:**
```bash
# Chá»‰ Ä‘á»‹nh input/output file
python generate_predictions.py --input data/Eveluate.json --output data/predictions.json
```

**Output**: File `data/predictions.json` vá»›i cáº¥u trÃºc:

```json
[
  {
    "question": "TÃªn khoa há»c cá»§a ráº¯n X lÃ  gÃ¬?",
    "ground_truth": "TÃªn khoa há»c lÃ  ABC xyz",
    "contexts": [
      "Context passage 1...",
      "Context passage 2...",
      "Context passage 3..."
    ],
    "answer": "TÃªn khoa há»c cá»§a ráº¯n X lÃ  ABC xyz..."
  }
]
```

**Thá»i gian**: TÃ¹y sá»‘ cÃ¢u há»i
- 100 cÃ¢u: ~5-10 phÃºt
- 500 cÃ¢u: ~20-30 phÃºt

### BÆ¯á»šC 2: Evaluate vá»›i RAGAS

ÄÃ¡nh giÃ¡ file predictions báº±ng RAGAS:

```bash
python evaluate_ragas.py
```

**Options:**

```bash
# Chá»‰ Ä‘á»‹nh input/output
python evaluate_ragas.py --input data/predictions.json --output my_results.json

# Chá»n metrics cá»¥ thá»ƒ
python evaluate_ragas.py --metrics faithfulness answer_correctness

# Táº¥t cáº£ metrics
python evaluate_ragas.py --metrics all
```

**Output**: 
- `evaluation_results.json` - Káº¿t quáº£ Ä‘áº§y Ä‘á»§
- `evaluation_results.csv` - Báº£ng dá»¯ liá»‡u

## ğŸ¯ RAGAS Metrics

| Metric | Ã nghÄ©a | ÄÃ¡nh giÃ¡ gÃ¬? |
|--------|---------|--------------|
| **Faithfulness** | Äá»™ trung thá»±c | CÃ¢u tráº£ lá»i cÃ³ nháº¥t quÃ¡n vá»›i contexts khÃ´ng? |
| **Answer Relevancy** | Äá»™ liÃªn quan | CÃ¢u tráº£ lá»i cÃ³ liÃªn quan Ä‘áº¿n cÃ¢u há»i khÃ´ng? |
| **Context Precision** | Äá»™ chÃ­nh xÃ¡c context | Contexts cÃ³ cháº¥t lÆ°á»£ng cao khÃ´ng? |
| **Context Recall** | Äá»™ phá»§ context | ÄÃ£ láº¥y Ä‘á»§ thÃ´ng tin cáº§n thiáº¿t chÆ°a? |
| **Answer Similarity** | Äá»™ tÆ°Æ¡ng Ä‘á»“ng | Giá»‘ng ground truth vá» máº·t ngá»¯ nghÄ©a? |
| **Answer Correctness** | Äá»™ chÃ­nh xÃ¡c | Tá»•ng há»£p: chÃ­nh xÃ¡c + tÆ°Æ¡ng Ä‘á»“ng |

### CÃ¡ch hiá»ƒu Ä‘iá»ƒm sá»‘

- **> 0.7**: Tá»‘t âœ…
- **0.5 - 0.7**: Trung bÃ¬nh âš ï¸
- **< 0.5**: Cáº§n cáº£i thiá»‡n âŒ

## ğŸ“Š PhÃ¢n tÃ­ch káº¿t quáº£

### 1. Xem Ä‘iá»ƒm tá»•ng quan

```bash
# Xem trong terminal khi cháº¡y evaluate_ragas.py
RAGAS SCORES
============================================================
faithfulness        : 0.8234
answer_relevancy    : 0.7891
context_precision   : 0.8012
context_recall      : 0.7543
answer_similarity   : 0.8156
answer_correctness  : 0.7923
============================================================
```

### 2. Xem chi tiáº¿t trong CSV

Má»Ÿ `evaluation_results.csv` trong Excel/Google Sheets Ä‘á»ƒ:
- Xem tá»«ng cÃ¢u há»i, cÃ¢u tráº£ lá»i
- So sÃ¡nh answer vs ground_truth
- TÃ¬m cÃ¡c cÃ¢u tráº£ lá»i sai
- PhÃ¢n tÃ­ch patterns

### 3. Xem full data trong JSON

File `evaluation_results.json` chá»©a:
```json
{
  "ragas_scores": {
    "faithfulness": 0.8234,
    ...
  },
  "predictions": [...],
  "summary": {...}
}
```

## ğŸ”„ Workflow hoÃ n chá»‰nh

### Láº§n Ä‘áº§u cháº¡y:

```bash
# BÆ°á»›c 0: Äáº£m báº£o Ä‘Ã£ cÃ³ vector index
python main.py

# BÆ°á»›c 1: Generate predictions
python generate_predictions.py

# BÆ°á»›c 2: Evaluate
python evaluate_ragas.py
```

### Khi thá»­ nghiá»‡m cáº£i thiá»‡n:

```bash
# 1. Thay Ä‘á»•i config (chunk_size, reranking, etc.)
# Edit config/config.py

# 2. Rebuild index náº¿u cáº§n
python main.py

# 3. Generate predictions má»›i
python generate_predictions.py --output data/predictions_v2.json

# 4. Evaluate
python evaluate_ragas.py --input data/predictions_v2.json --output results_v2.json

# 5. So sÃ¡nh vá»›i version cÅ©
```

## ğŸ’¡ Tips & Best Practices

### 1. Test nhá» trÆ°á»›c

```bash
# Táº¡o file test nhá»
head -n 10 data/Eveluate.json > data/test_10.json

# Generate predictions
python generate_predictions.py --input data/test_10.json --output data/test_predictions.json

# Evaluate
python evaluate_ragas.py --input data/test_predictions.json --output test_results.json
```

### 2. Backup predictions

```bash
# LÆ°u predictions Ä‘á»ƒ khÃ´ng pháº£i generate láº¡i
cp data/predictions.json data/predictions_backup_$(date +%Y%m%d).json
```

### 3. Compare versions

Táº¡o script Ä‘á»ƒ so sÃ¡nh:
```python
import json

with open('results_v1.json') as f:
    v1 = json.load(f)
    
with open('results_v2.json') as f:
    v2 = json.load(f)

for metric in v1['ragas_scores']:
    diff = v2['ragas_scores'][metric] - v1['ragas_scores'][metric]
    print(f"{metric}: {diff:+.4f}")
```

### 4. Track experiments

Táº¡o file `experiments.md`:
```markdown
# Experiment Log

## Baseline (2025-10-19)
- Config: chunk_size=400, rerank=True
- Faithfulness: 0.8234
- Answer Correctness: 0.7923

## Experiment 1 (2025-10-19)
- Changes: Increased chunk_size to 600
- Faithfulness: 0.8456 (+0.0222) âœ…
- Answer Correctness: 0.8012 (+0.0089) âœ…
```

## âŒ Troubleshooting

### Lá»—i: No index found

```bash
# Fix: Táº¡o index trÆ°á»›c
python main.py
```

### Lá»—i: Import ragas failed

```bash
# Fix: CÃ i Ä‘áº·t láº¡i
pip install ragas datasets pandas --upgrade
```

### Predictions cÃ³ contexts rá»—ng

**NguyÃªn nhÃ¢n**: Vector store khÃ´ng cÃ³ data hoáº·c embedding failed

**Fix**:
1. Check index: `ls -lh faiss_index.index` hoáº·c check Qdrant dashboard
2. Rebuild index: `python main.py`
3. Generate láº¡i: `python generate_predictions.py`

### RAGAS evaluation quÃ¡ cháº­m

**NguyÃªn nhÃ¢n**: RAGAS cáº§n gá»i LLM nhiá»u láº§n

**Solutions**:
1. Evaluate vá»›i Ã­t metrics hÆ¡n: `--metrics faithfulness answer_correctness`
2. Test vá»›i dataset nhá» trÆ°á»›c
3. Sá»­ dá»¥ng API key cÃ³ rate limit cao hÆ¡n

### Lá»—i: rate limit exceeded

**Fix**: 
1. Wait vÃ  retry
2. ThÃªm delay trong code
3. Upgrade API plan

## ğŸ“ˆ Cáº£i thiá»‡n Ä‘iá»ƒm sá»‘

### Faithfulness tháº¥p
â†’ Cáº£i thiá»‡n context quality:
- TÄƒng chunk size
- Improve chunking strategy
- Enable reranking

### Answer Relevancy tháº¥p  
â†’ Tune LLM prompt:
- RÃµ rÃ ng hÆ¡n trong prompt
- Add examples
- Äiá»u chá»‰nh temperature

### Context Precision/Recall tháº¥p
â†’ Optimize retrieval:
- Tune top_k
- Improve embedding quality
- Better reranking

### Answer Correctness tháº¥p
â†’ Tá»•ng há»£p:
- Check ground_truth quality
- Improve contexts + LLM prompt
- Fine-tune retrieval

## ğŸ“ Giáº£i thÃ­ch chi tiáº¿t metrics

### Faithfulness (Äá»™ trung thá»±c)

**Äo lÆ°á»ng**: Táº¥t cáº£ claims trong answer cÃ³ Ä‘Æ°á»£c support bá»Ÿi contexts khÃ´ng?

**CÃ¡ch tÃ­nh**: 
```
Faithfulness = (Sá»‘ claims Ä‘Æ°á»£c support) / (Tá»•ng sá»‘ claims)
```

**VÃ­ dá»¥**:
- Answer: "Ráº¯n lá»¥c cÃ³ ná»c Ä‘á»™c vÃ  sá»‘ng á»Ÿ rá»«ng"
- Contexts: "Ráº¯n lá»¥c lÃ  loÃ i cÃ³ ná»c Ä‘á»™c..."
- â†’ Claim 1 âœ… (cÃ³ ná»c), Claim 2 âŒ (khÃ´ng mention rá»«ng)
- â†’ Faithfulness = 0.5

### Answer Relevancy (Äá»™ liÃªn quan)

**Äo lÆ°á»ng**: Answer cÃ³ tráº£ lá»i Ä‘Ãºng cÃ¢u há»i khÃ´ng?

**CÃ¡ch tÃ­nh**: RAGAS generate questions tá»« answer, so vá»›i original question

**VÃ­ dá»¥**:
- Question: "Ráº¯n lá»¥c sá»‘ng á»Ÿ Ä‘Ã¢u?"
- Answer: "Ráº¯n lá»¥c cÃ³ ná»c Ä‘á»™c máº¡nh" â†’ âŒ KhÃ´ng relevant
- Answer: "Ráº¯n lá»¥c sá»‘ng á»Ÿ rá»«ng nhiá»‡t Ä‘á»›i" â†’ âœ… Relevant

### Context Precision (Äá»™ chÃ­nh xÃ¡c context)

**Äo lÆ°á»ng**: Contexts cÃ³ liÃªn quan cÃ³ rank cao hÆ¡n khÃ´ng?

**CÃ¡ch tÃ­nh**: Kiá»ƒm tra relevant contexts cÃ³ á»Ÿ top khÃ´ng

**VÃ­ dá»¥**:
```
Contexts: [relevant, irrelevant, relevant, irrelevant, relevant]
â†’ Precision tháº¥p (relevant bá»‹ xen káº½)

Contexts: [relevant, relevant, relevant, irrelevant, irrelevant]  
â†’ Precision cao (relevant á»Ÿ top)
```

### Context Recall (Äá»™ phá»§ context)

**Äo lÆ°á»ng**: Ground truth cÃ³ Ä‘Æ°á»£c support bá»Ÿi contexts khÃ´ng?

**CÃ¡ch tÃ­nh**: 
```
Recall = (Sentences in ground_truth cÃ³ trong contexts) / (Total sentences)
```

## ğŸ“š Tham kháº£o

- [RAGAS Documentation](https://docs.ragas.io/)
- [RAGAS GitHub](https://github.com/explodinggradients/ragas)
- [RAGAS Paper](https://arxiv.org/abs/2309.15217)

## ğŸ¯ Checklist

TrÆ°á»›c khi cháº¡y evaluation:

- [ ] ÄÃ£ cÃ i Ä‘áº·t: `pip install ragas datasets pandas`
- [ ] CÃ³ file `data/Eveluate.json` vá»›i format Ä‘Ãºng
- [ ] ÄÃ£ cháº¡y `python main.py` Ä‘á»ƒ táº¡o index
- [ ] API keys Ä‘Ã£ configured trong `.env`
- [ ] Test vá»›i dataset nhá» trÆ°á»›c

Sau khi cÃ³ káº¿t quáº£:

- [ ] Review RAGAS scores
- [ ] Xem CSV Ä‘á»ƒ phÃ¢n tÃ­ch chi tiáº¿t
- [ ] Document trong experiment log
- [ ] Backup predictions vÃ  results
- [ ] Plan cáº£i thiá»‡n dá»±a trÃªn scores

---

**Happy Evaluating! ğŸ‰**
