"""
Filter v√† x√≥a c√°c c√¢u tr·∫£ l·ªùi c√≥ BERTScore th·∫•p nh·∫•t
Input: 
    - data/Evaluation_documents/bertscore_evaluation_results.json (ƒë·ªÉ ph√¢n t√≠ch)
    - data/predictions.json (ƒë·ªÉ x√≥a c√¢u tr·∫£ l·ªùi)
Output: 
    - Ph√¢n t√≠ch Score Range
    - Cho ph√©p ch·ªçn x√≥a top-k c√¢u tr·∫£ l·ªùi k√©m nh·∫•t
    - predictions_cleaned.json (file m·ªõi sau khi x√≥a)
"""

import json
import os
from typing import List, Dict, Tuple
from collections import Counter


def load_json(filepath: str) -> dict:
    """Load JSON file"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return json.load(f)


def save_json(data: dict, filepath: str):
    """Save JSON file"""
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def analyze_score_distribution(results: List[Dict]) -> Dict:
    """
    Ph√¢n t√≠ch ph√¢n ph·ªëi ƒëi·ªÉm F1 theo range
    
    Returns:
        Dictionary v·ªõi th·ªëng k√™ t·ª´ng range
    """
    ranges = {
        "Excellent [0.9-1.0)": (0.9, 1.0),
        "Very Good [0.8-0.9)": (0.8, 0.9),
        "Good [0.7-0.8)": (0.7, 0.8),
        "Fair [0.6-0.7)": (0.6, 0.7),
        "Poor [0.0-0.6)": (0.0, 0.6)
    }
    
    distribution = {name: [] for name in ranges.keys()}
    
    # Ph√¢n lo·∫°i t·ª´ng c√¢u tr·∫£ l·ªùi
    for item in results:
        f1_score = item['bertscore']['f1']
        
        for range_name, (low, high) in ranges.items():
            if low <= f1_score < high:
                distribution[range_name].append(item)
                break
    
    return distribution


def print_score_analysis(distribution: Dict, total: int):
    """In ra ph√¢n t√≠ch Score Range"""
    print("\n" + "="*70)
    print("SCORE RANGE ANALYSIS")
    print("="*70)
    print("\nScore Range Analysis:")
    
    for range_name, items in distribution.items():
        count = len(items)
        percentage = (count / total) * 100 if total > 0 else 0
        
        # Format range name
        name_parts = range_name.split('[')
        label = name_parts[0].strip()
        range_str = '[' + name_parts[1] if len(name_parts) > 1 else ''
        
        print(f"  {label:12s} {range_str:12s} {count:4d} answers ({percentage:5.1f}%)")
    
    print(f"\n  {'Total':12s} {'':12s} {total:4d} answers (100.0%)")
    print("="*70)


def get_lowest_score_items(results: List[Dict], k: int) -> List[Dict]:
    """
    L·∫•y k c√¢u tr·∫£ l·ªùi c√≥ F1 score th·∫•p nh·∫•t
    
    Args:
        results: List c√°c k·∫øt qu·∫£ ƒë√°nh gi√°
        k: S·ªë l∆∞·ª£ng c√¢u c·∫ßn l·∫•y
    
    Returns:
        List k c√¢u c√≥ ƒëi·ªÉm th·∫•p nh·∫•t
    """
    # Sort theo F1 score tƒÉng d·∫ßn
    sorted_results = sorted(results, key=lambda x: x['bertscore']['f1'])
    return sorted_results[:k]


def print_low_quality_samples(items: List[Dict], k: int):
    """In ra c√°c m·∫´u c√≥ ch·∫•t l∆∞·ª£ng th·∫•p"""
    print(f"\n{'='*70}")
    print(f"TOP {k} LOWEST QUALITY ANSWERS")
    print("="*70)
    
    for i, item in enumerate(items, 1):
        f1 = item['bertscore']['f1']
        precision = item['bertscore']['precision']
        recall = item['bertscore']['recall']
        question = item['question']
        
        print(f"\n[{i}] F1={f1:.4f} | P={precision:.4f} | R={recall:.4f}")
        print(f"    Question: {question[:100]}...")
        print(f"    Ground truth: {item['ground_truth'][:80]}...")
        print(f"    Answer: {item['predicted_answer'][:80]}...")


def remove_items_from_predictions(predictions_file: str, 
                                  questions_to_remove: List[str],
                                  output_file: str) -> Tuple[int, int]:
    """
    X√≥a c√°c c√¢u tr·∫£ l·ªùi kh·ªèi predictions.json
    
    Args:
        predictions_file: File predictions.json g·ªëc
        questions_to_remove: List c√¢u h·ªèi c·∫ßn x√≥a
        output_file: File output sau khi x√≥a
    
    Returns:
        (original_count, final_count)
    """
    # Load predictions
    predictions = load_json(predictions_file)
    original_count = len(predictions)
    
    # T·∫°o set ƒë·ªÉ lookup nhanh
    questions_set = set(questions_to_remove)
    
    # Filter ra c√°c item kh√¥ng n·∫±m trong danh s√°ch x√≥a
    filtered_predictions = [
        pred for pred in predictions 
        if pred['question'] not in questions_set
    ]
    
    final_count = len(filtered_predictions)
    
    # Save file m·ªõi
    save_json(filtered_predictions, output_file)
    
    return original_count, final_count


def main():
    """Main function"""
    print("="*70)
    print("LOW QUALITY ANSWER FILTER & REMOVER")
    print("="*70)
    
    # File paths
    bertscore_file = "data/Evaluation_documents/bertscore_evaluation_results.json"
    predictions_file = "data/predictions.json"
    output_file = "data/predictions_cleaned.json"
    
    # Load BERTScore results
    print(f"\n[1/5] Loading BERTScore results from {bertscore_file}...")
    bertscore_data = load_json(bertscore_file)
    results = bertscore_data['per_question_results']
    total = len(results)
    print(f"    ‚úì Loaded {total} evaluation results")
    
    # Analyze score distribution
    print(f"\n[2/5] Analyzing score distribution...")
    distribution = analyze_score_distribution(results)
    print_score_analysis(distribution, total)
    
    # Get poor quality count
    poor_count = len(distribution["Poor [0.0-0.6)"])
    fair_count = len(distribution["Fair [0.6-0.7)"])
    
    print(f"\nüí° Suggestions:")
    print(f"   - Poor quality (F1 < 0.6): {poor_count} answers")
    print(f"   - Fair quality (F1 < 0.7): {fair_count + poor_count} answers")
    print(f"   - Total available for removal: {total} answers")
    
    # Get user input
    print(f"\n[3/5] Select number of lowest quality answers to remove...")
    while True:
        try:
            k = int(input(f"    Enter number (1-{total}), or 0 to cancel: "))
            if k == 0:
                print("\n‚ùå Operation cancelled by user")
                return
            if 1 <= k <= total:
                break
            print(f"    ‚ö†Ô∏è  Please enter a number between 1 and {total}")
        except ValueError:
            print("    ‚ö†Ô∏è  Please enter a valid number")
    
    # Get lowest score items
    print(f"\n[4/5] Finding top {k} lowest quality answers...")
    lowest_items = get_lowest_score_items(results, k)
    print_low_quality_samples(lowest_items, k)
    
    # Confirm removal
    print(f"\n{'='*70}")
    print(f"‚ö†Ô∏è  WARNING: You are about to remove {k} answers from predictions.json")
    print(f"{'='*70}")
    confirm = input("\n    Type 'yes' to confirm removal: ").strip().lower()
    
    if confirm != 'yes':
        print("\n‚ùå Removal cancelled")
        return
    
    # Remove from predictions
    print(f"\n[5/5] Removing {k} answers from predictions...")
    questions_to_remove = [item['question'] for item in lowest_items]
    
    original_count, final_count = remove_items_from_predictions(
        predictions_file, 
        questions_to_remove,
        output_file
    )
    
    removed_count = original_count - final_count
    
    print(f"\n{'='*70}")
    print("REMOVAL COMPLETE")
    print("="*70)
    print(f"  Original predictions: {original_count}")
    print(f"  Removed answers:      {removed_count}")
    print(f"  Remaining predictions: {final_count}")
    print(f"\n  ‚úì Cleaned file saved to: {output_file}")
    print("="*70)
    
    # Statistics of removed items
    removed_f1_scores = [item['bertscore']['f1'] for item in lowest_items]
    avg_removed_f1 = sum(removed_f1_scores) / len(removed_f1_scores)
    min_removed_f1 = min(removed_f1_scores)
    max_removed_f1 = max(removed_f1_scores)
    
    print(f"\nüìä Removed Items Statistics:")
    print(f"   - Average F1: {avg_removed_f1:.4f}")
    print(f"   - Min F1:     {min_removed_f1:.4f}")
    print(f"   - Max F1:     {max_removed_f1:.4f}")
    print("\nüí° Next steps:")
    print(f"   1. Review cleaned file: {output_file}")
    print(f"   2. If satisfied, replace original: mv {output_file} {predictions_file}")
    print(f"   3. Re-run evaluation to see improved scores")
    print("="*70)


if __name__ == "__main__":
    main()
