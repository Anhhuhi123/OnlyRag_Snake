# RAG Pipeline - Há»‡ thá»‘ng Tra cá»©u ThÃ´ng tin Ráº¯n Viá»‡t Nam

Há»‡ thá»‘ng RAG (Retrieval-Augmented Generation) hoÃ n chá»‰nh sá»­ dá»¥ng Google Gemini, Qdrant Cloud vÃ  Cross-Encoder Re-ranking Ä‘á»ƒ tra cá»©u thÃ´ng tin vá» cÃ¡c loÃ i ráº¯n táº¡i Viá»‡t Nam.

## âœ¨ TÃ­nh nÄƒng ná»•i báº­t

- **ğŸ¤– Gemini 2.5 Flash LLM** - MÃ´ hÃ¬nh ngÃ´n ngá»¯ tiÃªn tiáº¿n cho viá»‡c sinh cÃ¢u tráº£ lá»i
- **ğŸ” Gemini Embedding (3072 chiá»u)** - Embedding cháº¥t lÆ°á»£ng cao cho tÃ¬m kiáº¿m ngá»¯ nghÄ©a
- **â˜ï¸ Qdrant Cloud Vector Store** - CÆ¡ sá»Ÿ dá»¯ liá»‡u vector trÃªn cloud, thay tháº¿ FAISS local
- **ğŸ¯ Cross-Encoder Re-ranking** - Sáº¯p xáº¿p láº¡i káº¿t quáº£ vá»›i ms-marco-MiniLM-L-12-v2
- **âš¡ Rate Limiting thÃ´ng minh** - Batching tá»± Ä‘á»™ng vÃ  exponential backoff cho Gemini API
- **ğŸ“„ Document Processing** - Chunking vÃ  tiá»n xá»­ lÃ½ vÄƒn báº£n thÃ´ng minh
- **ğŸ—ï¸ Kiáº¿n trÃºc module hÃ³a** - Code sáº¡ch, dá»… báº£o trÃ¬ vÃ  má»Ÿ rá»™ng
- **ğŸ“Š JSON Structured Data** - Há»— trá»£ 13 trÆ°á»ng dá»¯ liá»‡u chuyÃªn biá»‡t cho tá»«ng loÃ i ráº¯n

## ğŸ“‚ Cáº¥u trÃºc thÆ° má»¥c

```
RAG/
â”œâ”€â”€ README.md                     # HÆ°á»›ng dáº«n chi tiáº¿t
â”œâ”€â”€ QDRANT_GUIDE.md              # HÆ°á»›ng dáº«n sá»­ dá»¥ng Qdrant Cloud
â”œâ”€â”€ TROUBLESHOOTING.md           # Kháº¯c phá»¥c sá»± cá»‘
â”œâ”€â”€ requirements.txt              # ThÆ° viá»‡n Python cáº§n thiáº¿t
â”œâ”€â”€ .env                         # Biáº¿n mÃ´i trÆ°á»ng (API keys)
â”œâ”€â”€ main.py                      # Äiá»ƒm vÃ o chÃ­nh cá»§a há»‡ thá»‘ng
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.py                # Quáº£n lÃ½ cáº¥u hÃ¬nh toÃ n há»‡ thá»‘ng
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ embeddings.py            # Táº¡o embedding vá»›i Gemini (cÃ³ batching)
â”‚   â”œâ”€â”€ vector_store.py          # FAISS vector store (local)
â”‚   â”œâ”€â”€ qdrant_vector_store.py   # Qdrant Cloud vector store
â”‚   â”œâ”€â”€ llm.py                   # Gemini 2.5 Flash LLM
â”‚   â”œâ”€â”€ document_processor.py    # Xá»­ lÃ½ vÃ  chunking document
â”‚   â”œâ”€â”€ reranker.py              # Cross-encoder re-ranking
â”‚   â””â”€â”€ rag_pipeline.py          # Orchestrator chÃ­nh cá»§a RAG
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ document_RAG.json        # Dá»¯ liá»‡u 45 loÃ i ráº¯n (13 fields/loÃ i)
â”‚   â””â”€â”€ json_loader.py           # Load vÃ  xá»­ lÃ½ JSON data
â”‚
â””â”€â”€ examples/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ demo.py                  # Script demo vÃ  test
```

## ğŸš€ CÃ i Ä‘áº·t

### 1. Clone repository

```bash
git clone https://github.com/Anhhuhi123/Rank-F1.git
cd RAG
```

### 2. CÃ i Ä‘áº·t thÆ° viá»‡n

```bash
pip install -r requirements.txt
```

CÃ¡c thÆ° viá»‡n chÃ­nh:
- `google-genai` - Gemini API
- `qdrant-client` - Qdrant Cloud vector database
- `sentence-transformers` - Cross-encoder re-ranking
- `torch` - Deep learning framework
- `numpy`, `tqdm` - Utilities

### 3. Cáº¥u hÃ¬nh API Keys

Táº¡o file `.env` trong thÆ° má»¥c gá»‘c:

```bash
# Google Gemini API Key (Free tier: 15 requests/min, 1500 requests/day)
GOOGLE_API_KEY=your_gemini_api_key_here

# Qdrant Cloud Configuration
QDRANT_URL=https://your-cluster.cloud.qdrant.io:6333
QDRANT_API_KEY=your_qdrant_api_key_here
```

**Láº¥y API Keys:**
- **Gemini API**: https://aistudio.google.com/app/apikey
- **Qdrant Cloud**: https://cloud.qdrant.io/ (ÄÄƒng kÃ½ free tier)

### 4. Cáº¥u hÃ¬nh há»‡ thá»‘ng

Chá»‰nh sá»­a `config/config.py` náº¿u cáº§n:

```python
# Vector Store (chá»n Qdrant hoáº·c FAISS)
USE_QDRANT = True  # True = Qdrant Cloud, False = FAISS local

# Re-ranking
USE_RERANKING = True
RERANK_TOP_K = 10      # Láº¥y 10 káº¿t quáº£ tá»« vector store
FINAL_TOP_K = 5        # Sau re-ranking chá»‰ giá»¯ 5 káº¿t quáº£ tá»‘t nháº¥t
RERANK_ALPHA = 0.7     # 70% cross-encoder + 30% original score

# Rate Limiting
EMBEDDING_BATCH_SIZE = 100  # Gemini API giá»›i háº¡n 100 items/request
EMBEDDING_DELAY = 5.0       # Äá»£i 5 giÃ¢y giá»¯a cÃ¡c batch
```

## ğŸ¯ HÆ°á»›ng dáº«n sá»­ dá»¥ng

### 1ï¸âƒ£ Ingest dá»¯ liá»‡u (Láº§n Ä‘áº§u tiÃªn)

**Ingest toÃ n bá»™ document:**
```bash
python main.py --ingest data/document_RAG.json
```

**Ingest vá»›i trÆ°á»ng cá»¥ thá»ƒ:**
```bash
python main.py --ingest data/document_RAG.json --json-fields 'TÃªn khoa há»c vÃ  tÃªn phá»• thÃ´ng'
```

**Ingest nhiá»u trÆ°á»ng:**
```bash
python main.py --ingest data/document_RAG.json --json-fields 'TÃªn khoa há»c vÃ  tÃªn phá»• thÃ´ng' 'Äáº·c Ä‘iá»ƒm nháº­n dáº¡ng' 'Äá»™c tÃ­nh'
```

QuÃ¡ trÃ¬nh nÃ y sáº½:
- Äá»c file JSON chá»©a thÃ´ng tin 124 loÃ i ráº¯n
- Chia nhá» vÄƒn báº£n thÃ nh chunks (chunk_size=40, overlap=7)
- Táº¡o embeddings vá»›i Gemini (batching tá»± Ä‘á»™ng)
- LÆ°u vÃ o Qdrant Cloud (hoáº·c FAISS náº¿u USE_QDRANT=False)

### 2ï¸âƒ£ Tra cá»©u thÃ´ng tin

**Query Ä‘Æ¡n giáº£n:**
```bash
python main.py --query "Ráº¯n há»• mang chÃºa lÃ  ráº¯n Ä‘á»™c hay khÃ´ng Ä‘á»™c?"
```

**Query phá»©c táº¡p:**
```bash
python main.py --query "Nhá»¯ng loÃ i ráº¯n nÃ o á»Ÿ Viá»‡t Nam cÃ³ mÃ u xanh lÃ¡ cÃ¢y?"
```

### 3ï¸âƒ£ Cháº¿ Ä‘á»™ interactive

```bash
python main.py --demo
```

Hoáº·c cháº¡y trá»±c tiáº¿p:
```bash
python examples/demo.py
```

### 4ï¸âƒ£ Test re-ranking

```bash
python test_reranking.py
```

### 5ï¸âƒ£ Test Qdrant connection

```bash
python test_qdrant.py
```

## ğŸ“Š Luá»“ng hoáº¡t Ä‘á»™ng tá»•ng thá»ƒ

### ğŸ”¹ Giai Ä‘oáº¡n 1: Ingest Documents (Chá»‰ cháº¡y 1 láº§n)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ document_RAG.json   â”‚      
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  JSONLoader.load_from_json()                â”‚
â”‚  - Äá»c JSON vá»›i 13 fields/loÃ i              â”‚
â”‚  - Chá»n fields cá»¥ thá»ƒ (náº¿u cÃ³ --json-fields)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DocumentProcessor.process_documents()       â”‚
â”‚  - Chunk vÄƒn báº£n (size=40, overlap=7)       â”‚
â”‚  - Tá»•ng: ~258 chunks tá»« 45 documents        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EmbeddingGenerator.generate_embeddings()    â”‚
â”‚  - Chia thÃ nh batches (100 items/batch)     â”‚
â”‚  - 258 chunks â†’ 3 requests                  â”‚
â”‚  - Äá»£i 5s giá»¯a cÃ¡c batch                    â”‚
â”‚  - Exponential backoff náº¿u 429 error        â”‚
â”‚  - Output: 258 vectors Ã— 3072 dimensions    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  QdrantVectorStore.add_embeddings()          â”‚
â”‚  - Upload lÃªn Qdrant Cloud                  â”‚
â”‚  - Collection: snake_knowledge_base         â”‚
â”‚  - Metric: Cosine similarity                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Chi tiáº¿t rate limiting:**
- Gemini Free Tier: 15 requests/minute, 1,500 requests/day
- Batching: 258 chunks / 100 per batch = 3 requests
- Delay: 5 giÃ¢y giá»¯a má»—i batch â†’ tá»•ng ~15 giÃ¢y
- Náº¿u lá»—i 429: Retry vá»›i exponential backoff (2s â†’ 4s â†’ 8s)

### ğŸ”¹ Giai Ä‘oáº¡n 2: Query Processing (Má»—i láº§n há»i)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Query         â”‚
â”‚  "Ráº¯n há»• mang       â”‚
â”‚   chÃºa Ä‘á»™c khÃ´ng?"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EmbeddingGenerator.generate_single_embeddingâ”‚
â”‚  - Táº¡o query embedding (3072 dim)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  QdrantVectorStore.search()                  â”‚
â”‚  - TÃ¬m kiáº¿m vector similarity               â”‚
â”‚  - Láº¥y top-10 chunks (RERANK_TOP_K=10)      â”‚
â”‚  - Cosine distance ranking                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CrossEncoderReranker.rerank()               â”‚
â”‚  - Model: ms-marco-MiniLM-L-12-v2           â”‚
â”‚  - Re-score 10 chunks dá»±a trÃªn query        â”‚
â”‚  - Káº¿t há»£p scores: 70% cross-encoder +      â”‚
â”‚                    30% original similarity  â”‚
â”‚  - Chá»n top-5 chunks tá»‘t nháº¥t               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM.generate_response()                     â”‚
â”‚  - Model: Gemini 2.5 Flash                  â”‚
â”‚  - Context: 5 chunks Ä‘Æ°á»£c re-rank           â”‚
â”‚  - Prompt: Question + Context               â”‚
â”‚  - Sinh cÃ¢u tráº£ lá»i tá»± nhiÃªn                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Final Answer       â”‚
â”‚  + Sources          â”‚
â”‚  + Scores           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”¹ Chi tiáº¿t Re-ranking

```
Input: 10 passages tá»« Qdrant (RERANK_TOP_K=10)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cross-Encoder Scoring                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  For each passage:                           â”‚
â”‚    - Input: [query, passage] pair           â”‚
â”‚    - Model: ms-marco-MiniLM-L-12-v2         â”‚
â”‚    - Output: relevance score (0-1)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Score Fusion (alpha=0.7)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  final_score = 0.7 Ã— cross_encoder_score    â”‚
â”‚              + 0.3 Ã— original_cosine_score  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Re-sort vÃ  láº¥y top-5 (FINAL_TOP_K=5)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Output: 5 passages tá»‘t nháº¥t â†’ Gá»­i vÃ o LLM
```

## ğŸ› ï¸ Cáº¥u hÃ¬nh nÃ¢ng cao

### Chuyá»ƒn Ä‘á»•i giá»¯a Qdrant vÃ  FAISS

**Sá»­ dá»¥ng Qdrant Cloud (Khuyáº¿n nghá»‹):**
```python
# config/config.py
USE_QDRANT = True
```

**Sá»­ dá»¥ng FAISS Local:**
```python
# config/config.py
USE_QDRANT = False
```

### Táº¯t Re-ranking

```python
# config/config.py
USE_RERANKING = False
```

### Äiá»u chá»‰nh chunking

```python
# config/config.py
CHUNK_SIZE = 40        # Sá»‘ words/chunk
CHUNK_OVERLAP = 7      # Sá»‘ words overlap giá»¯a chunks
```

### Äiá»u chá»‰nh retrieval

```python
# config/config.py
RERANK_TOP_K = 10      # Sá»‘ chunks láº¥y tá»« vector store
FINAL_TOP_K = 5        # Sá»‘ chunks sau re-ranking
RERANK_ALPHA = 0.7     # Trá»ng sá»‘ cross-encoder (0.0 - 1.0)
```

## ğŸ“ VÃ­ dá»¥ sá»­ dá»¥ng

### VÃ­ dá»¥ 1: Query vá» Ä‘á»™c tÃ­nh

```bash
python main.py --query "Ráº¯n lá»¥c Ä‘uÃ´i Ä‘á» cÃ³ Ä‘á»™c khÃ´ng?"
```

**Output:**
```
Query: Ráº¯n lá»¥c Ä‘uÃ´i Ä‘á» cÃ³ Ä‘á»™c khÃ´ng?
Processing query...
Generating query embedding...
  Processing batch 1/1 (1 texts)...
Searching vector store...
Found 10 candidate passages
Applying cross-encoder re-ranking...
Re-ranked to top 5 passages
Generating response...

Answer:
CÃ³, ráº¯n lá»¥c Ä‘uÃ´i Ä‘á» (Trimeresurus albolabris) lÃ  loÃ i ráº¯n Ä‘á»™c. 
Ná»c Ä‘á»™c cá»§a chÃºng cÃ³ thá»ƒ gÃ¢y Ä‘au, sÆ°ng vÃ  hoáº¡i tá»­ mÃ´ táº¡i chá»— cáº¯n...

Sources:
1. Trimeresurus albolabris - Ráº¯n lá»¥c Ä‘uÃ´i Ä‘á»... (Score: 0.95)
2. Äá»™c tÃ­nh cá»§a ráº¯n lá»¥c... (Score: 0.89)
...
```

### VÃ­ dá»¥ 2: Query vá» phÃ¢n bá»‘

```bash
python main.py --query "Nhá»¯ng loÃ i ráº¯n nÃ o sá»‘ng á»Ÿ miá»n Báº¯c Viá»‡t Nam?"
```

### VÃ­ dá»¥ 3: Ingest chá»‰ trÆ°á»ng Äá»™c tÃ­nh

```bash
python main.py --ingest data/document_RAG.json --json-fields 'Äá»™c tÃ­nh' 'Xá»­ lÃ½ khi bá»‹ cáº¯n'
```

## ğŸ› Kháº¯c phá»¥c sá»± cá»‘

### Lá»—i: 429 RESOURCE_EXHAUSTED

**NguyÃªn nhÃ¢n:** VÆ°á»£t quota Gemini API (15 requests/minute)

**Giáº£i phÃ¡p:**
1. TÄƒng `EMBEDDING_DELAY` trong `config/config.py`
2. Äá»£i API quota reset (00:00 UTC má»—i ngÃ y)
3. Upgrade lÃªn paid tier

### Lá»—i: 503 Model Overloaded

**NguyÃªn nhÃ¢n:** Gemini API quÃ¡ táº£i táº¡m thá»i

**Giáº£i phÃ¡p:**
- Äá»£i vÃ i phÃºt rá»“i thá»­ láº¡i
- Há»‡ thá»‘ng cÃ³ exponential backoff tá»± Ä‘á»™ng

### Model re-ranking táº£i cháº­m

**NguyÃªn nhÃ¢n:** Láº§n Ä‘áº§u download model tá»« HuggingFace

**Giáº£i phÃ¡p:**
- Äá»£i download hoÃ n táº¥t (~400MB)
- Model Ä‘Æ°á»£c cache táº¡i: `~/.cache/huggingface/hub/`

Xem thÃªm: [TROUBLESHOOTING.md](TROUBLESHOOTING.md)

## ğŸ“š TÃ i liá»‡u tham kháº£o

- [QDRANT_GUIDE.md](QDRANT_GUIDE.md) - HÆ°á»›ng dáº«n chi tiáº¿t vá» Qdrant Cloud
- [TROUBLESHOOTING.md](TROUBLESHOOTING.md) - Kháº¯c phá»¥c sá»± cá»‘ Ä‘áº§y Ä‘á»§

## ğŸ”— Links há»¯u Ã­ch

- **Gemini API**: https://aistudio.google.com/
- **Qdrant Cloud**: https://cloud.qdrant.io/
- **Sentence Transformers**: https://www.sbert.net/
- **Cross-Encoder Models**: https://www.sbert.net/docs/pretrained_cross-encoders.html

## ğŸ“Š Thá»‘ng kÃª há»‡ thá»‘ng

- **Sá»‘ loÃ i ráº¯n:** 124 loÃ i
- **Sá»‘ chunks:** ~258 chunks (sau chunking)
- **Embedding dimension:** 3072 (Gemini)
- **Vector store:** Qdrant Cloud
- **Re-ranking model:** ms-marco-MiniLM-L-12-v2
- **LLM:** Gemini 2.5 Flash

## ğŸ“ Kiáº¿n trÃºc ká»¹ thuáº­t

### Two-Stage Retrieval

1. **Stage 1 - Dense Retrieval (Qdrant)**
   - TÃ¬m kiáº¿m nhanh dá»±a trÃªn cosine similarity
   - Láº¥y top-10 candidates (recall cao)

2. **Stage 2 - Cross-Encoder Re-ranking**
   - ÄÃ¡nh giÃ¡ chÃ­nh xÃ¡c tá»«ng passage vá»›i query
   - Láº¥y top-5 final results (precision cao)

### Rate Limiting Strategy

```python
# Gemini API Limits
Free Tier: 15 requests/minute, 1,500 requests/day

# Batching Strategy
- Batch size: 100 items/request (max cá»§a API)
- Delay: 5 seconds between batches
- Exponential backoff: 2s â†’ 4s â†’ 8s (max 3 retries)

# Example: 258 chunks
258 / 100 = 3 requests
3 requests Ã— 5s delay = 15 seconds total
```

## ğŸ‘¥ ÄÃ³ng gÃ³p

Má»i Ä‘Ã³ng gÃ³p Ä‘á»u Ä‘Æ°á»£c hoan nghÃªnh! Vui lÃ²ng táº¡o Pull Request hoáº·c má»Ÿ Issue.

## ğŸ“„ License

MIT License

---

**PhÃ¡t triá»ƒn bá»Ÿi:** Anh Hu Hi  
**Repository:** https://github.com/Anhhuhi123/Rank-F1  
**NgÃ y cáº­p nháº­t:** 16/10/2025

### Command Line Interface

```bash
# Test all components
python main.py --test

# Ingest sample document
python main.py --ingest

# Ask a single question
python main.py --query "What are the five Sacred Temples?"

# Show pipeline statistics
python main.py --stats

# Reset the pipeline
python main.py --reset

# Run comprehensive demo
python main.py --demo
```

### Python API

```python
from src.rag_pipeline import RAGPipeline
from data.sample_story import get_sample_story

# Initialize pipeline
rag = RAGPipeline()

# Test components
test_results = rag.test_components()

# Ingest documents
sample_story = get_sample_story()
stats = rag.ingest_documents([sample_story])

# Query the pipeline
result = rag.query("Who is the main character?")
print(result["response"])
```

## Configuration

The pipeline can be configured through `config/config.py`:

```python
class Config:
    # Model configurations
    LLM_MODEL = "gemini-2.5-flash"
    EMBEDDING_MODEL = "gemini-embedding-001"
    EMBEDDING_BATCH_SIZE = 100  # Max batch size for Gemini API
    EMBEDDING_DELAY = 2.0       # Delay between batches to avoid rate limits
    
    # RAG configurations
    CHUNK_SIZE = 1000
    CHUNK_OVERLAP = 200
    TOP_K_RESULTS = 5
    
    # Re-ranking configurations
    USE_RERANKING = True
    CROSS_ENCODER_MODEL = "cross-encoder/ms-marco-MiniLM-L-12-v2"
    RERANK_TOP_K = 10        # Retrieve more candidates for re-ranking
    FINAL_TOP_K = 5          # Final number after re-ranking
    RERANK_ALPHA = 0.7       # Weight: 0.7 cross-encoder + 0.3 original score
    
    # FAISS configurations
    VECTOR_DIMENSION = 768
```

## Components

### 1. Embedding Generator (`src/embeddings.py`)
- Uses Gemini embedding model for text vectorization
- Supports batch and single text embedding generation
- Handles API communication and error management

### 2. Vector Store (`src/vector_store.py`)
- FAISS-based vector database for similarity search
- Supports saving/loading indexes to/from disk
- Implements cosine similarity search
- Provides statistics and management functions

### 3. LLM Interface (`src/llm.py`)
- Gemini 2.5 Flash integration for response generation
- Context-aware response generation
- Configurable thinking budget (disabled for faster responses)
- Error handling and fallback mechanisms

### 4. Document Processor (`src/document_processor.py`)
- Intelligent text chunking with overlap
- Text cleaning and normalization
- Sentence-aware splitting for better context preservation
- Configurable chunk sizes and overlap

### 5. Cross-encoder Re-ranker (`src/reranker.py`) ğŸ†•
- Uses `cross-encoder/ms-marco-MiniLM-L-12-v2` for passage re-ranking
- Combines original similarity scores with cross-encoder scores
- Configurable score combination weights (alpha parameter)
- Significantly improves retrieval quality and relevance

### 6. RAG Pipeline (`src/rag_pipeline.py`)
- Main orchestrator combining all components
- Document ingestion and indexing workflow
- Query processing with optional re-ranking
- Pipeline state management and statistics
- **Enhanced retrieval flow**: Vector search â†’ Cross-encoder re-ranking â†’ LLM generation

## Re-ranking Architecture

The pipeline now supports advanced two-stage retrieval:

```
Query â†’ Dense Retrieval (Top-10) â†’ Cross-encoder Re-ranking (Top-5) â†’ LLM Response
```

**Benefits of Re-ranking:**
- ğŸ¯ **Higher Precision**: Cross-encoder provides more accurate relevance scoring
- ğŸ”„ **Best of Both Worlds**: Combines fast dense retrieval with precise cross-encoder scoring  
- âš™ï¸ **Configurable**: Adjustable weights between original and cross-encoder scores
- ğŸ“Š **Transparent**: Detailed scoring information for analysis

## Sample Data

The pipeline includes a sample fantasy story "The Chronicles of Eldoria: The Last Guardian" for testing and demonstration purposes. The story contains rich narrative content perfect for testing RAG capabilities.

## Demo Features

The interactive demo (`examples/demo.py`) includes:

- **Component Testing** - Verify all components work correctly
- **Document Ingestion** - Process and index the sample story
- **Predefined Queries** - Test with curated questions
- **Interactive Mode** - Ask your own questions
- **Statistics Display** - View pipeline performance metrics

## API Key Setup

1. Get your Google API key from [Google AI Studio](https://aistudio.google.com/)
2. Add it to the `.env` file:
   ```
   GOOGLE_API_KEY=your_api_key_here
   ```

## Performance

- **Embedding Dimension**: 768 (Gemini embedding model)
- **Default Chunk Size**: 1000 characters
- **Default Overlap**: 200 characters
- **Default Top-K**: 5 results
- **Vector Search**: Cosine similarity with FAISS

## Error Handling

The pipeline includes comprehensive error handling:
- API key validation
- Network error recovery
- Malformed input handling
- Graceful degradation when components fail

## ğŸ“Š ÄÃ¡nh giÃ¡ vá»›i RAGAS

### Giá»›i thiá»‡u

RAGAS (Retrieval Augmented Generation Assessment) - Framework Ä‘Ã¡nh giÃ¡ RAG pipeline vá»›i 6 metrics:
- **Faithfulness**, **Answer Relevancy**, **Context Precision**, **Context Recall**, **Answer Similarity**, **Answer Correctness**

### Quick Start

```bash
# 1. CÃ i Ä‘áº·t RAGAS
pip install ragas datasets pandas

# 2. BÆ°á»›c 1: Generate predictions (contexts + answer)
python generate_predictions.py

# 3. BÆ°á»›c 2: Evaluate vá»›i RAGAS
python evaluate_ragas.py
```

### Quy trÃ¬nh 2 bÆ°á»›c

**BÆ°á»›c 1**: Generate predictions tá»« RAG
```
Input:  data/Eveluate.json (question, ground_truth)
        â†“
Run:    python generate_predictions.py
        â†“
Output: data/predictions.json (question, ground_truth, contexts, answer)
```

**BÆ°á»›c 2**: Evaluate báº±ng RAGAS
```
Input:  data/predictions.json
        â†“
Run:    python evaluate_ragas.py
        â†“
Output: evaluation_results.json + evaluation_results.csv
```

### Chi tiáº¿t

Xem **`RAGAS_GUIDE.md`** Ä‘á»ƒ biáº¿t:
- HÆ°á»›ng dáº«n chi tiáº¿t tá»«ng bÆ°á»›c
- Giáº£i thÃ­ch cÃ¡c metrics
- CÃ¡ch phÃ¢n tÃ­ch káº¿t quáº£
- Tips & troubleshooting

## Contributing

1. Fork the repository
2. Create a feature branch

**PhÃ¡t triá»ƒn bá»Ÿi:** Anh Hu Hi  
**Repository:** https://github.com/Anhhuhi123/Rank-F1  
**NgÃ y cáº­p nháº­t:** 19/10/2025